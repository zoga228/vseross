{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd89f0ee-f82c-46ec-87cd-519b36f88d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoPyTorch.api.tabular_classification import TabularClassificationTask\n",
    "from autoPyTorch.api.tabular_regression import TabularRegressionTask\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer, fetch_california_housing\n",
    "import numpy as np\n",
    "\n",
    "# Пример классификации\n",
    "# -------------------\n",
    "# Загрузка данных\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Создание задачи классификации\n",
    "api = TabularClassificationTask()\n",
    "\n",
    "# Настройка и запуск оптимизации\n",
    "api.search(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    optimize_metric='accuracy',\n",
    "    total_walltime_limit=3600,  # 1 час\n",
    "    func_eval_time_limit_secs=300,  # 5 минут на одну модель\n",
    "    memory_limit=8192,  # 8 ГБ\n",
    "    n_jobs=-1,  # Использовать все ядра\n",
    "    ensemble_size=5,  # Размер ансамбля\n",
    "    include_preprocessors=['feature_type', 'scaling', 'imputation'],\n",
    "    resampling_strategy='cv',\n",
    "    resampling_strategy_args={'folds': 5}\n",
    ")\n",
    "\n",
    "# Получение результатов\n",
    "y_pred = api.predict(X_test)\n",
    "print(f\"Test accuracy: {np.mean(y_pred == y_test)}\")\n",
    "\n",
    "# Получение вероятностей\n",
    "y_proba = api.predict_proba(X_test)\n",
    "\n",
    "# Получение лучшей модели\n",
    "best_model = api.get_best_model()\n",
    "\n",
    "# Пример регрессии\n",
    "# --------------\n",
    "# Загрузка данных\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Создание задачи регрессии\n",
    "api_reg = TabularRegressionTask()\n",
    "\n",
    "# Настройка и запуск оптимизации\n",
    "api_reg.search(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    optimize_metric='r2',\n",
    "    total_walltime_limit=3600,\n",
    "    func_eval_time_limit_secs=300,\n",
    "    memory_limit=8192,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Получение результатов\n",
    "y_pred = api_reg.predict(X_test)\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "print(f\"Test R2: {r2_score(y_test, y_pred)}\")\n",
    "print(f\"Test RMSE: {np.sqrt(mean_squared_error(y_test, y_pred))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a983888-ff13-407e-b70d-b73728d70446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoPyTorch.api.tabular_classification import TabularClassificationTask\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Создание задачи с настройкамими ансамбля\n",
    "api = TabularClassificationTask(\n",
    "    ensemble_size=10,  # Размер ансамбля\n",
    "    ensemble_nbest=5,  # Использовать 5 лучших моделей\n",
    "    max_models_on_disc=20,  # Хранить до 20 моделей\n",
    "    seed=42,\n",
    "    include_components={\n",
    "        'feature_preprocessor': ['pca', 'quantile_transformer', 'polynomial'],\n",
    "        'classifier': ['random_forest', 'extra_trees', 'adaboost', 'mlp', 'lgb']\n",
    "    }\n",
    ")\n",
    "\n",
    "# Запуск поиска с настройками для разнообразия моделей\n",
    "api.search(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    optimize_metric='balanced_accuracy',\n",
    "    total_walltime_limit=7200,  # 2 часа\n",
    "    func_eval_time_limit_secs=300,\n",
    "    memory_limit=8192,\n",
    "    ensemble_size=10,\n",
    "    ensemble_strategy='bagging',  # Использование бэггинга\n",
    "    resampling_strategy='cv',\n",
    "    resampling_strategy_args={'folds': 5}\n",
    ")\n",
    "\n",
    "# Получение результатов ансамбля\n",
    "y_pred = api.predict(X_test)\n",
    "y_proba = api.predict_proba(X_test)\n",
    "\n",
    "# Получение отдельных моделей из ансамбля\n",
    "ensemble_models = api.get_ensemble_models()\n",
    "\n",
    "# Использование отдельной модели из ансамбля\n",
    "single_model = ensemble_models[0]\n",
    "single_prediction = single_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e914cd76-b8bd-4e4d-823d-18c40585de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoPyTorch.api.nlp_task import NLPTask\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Предположим, у нас есть текстовые данные\n",
    "texts = [\"This is a positive text\", \"This is a negative example\", ...]\n",
    "labels = [1, 0, ...]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2)\n",
    "\n",
    "# Создание NLP задачи\n",
    "api = NLPTask(\n",
    "    language='english',\n",
    "    task_type='classification',\n",
    "    transformer_models=['bert-base-uncased', 'roberta-base'],\n",
    "    max_seq_length=128,\n",
    "    include_preprocessing_pipelines=['standard']\n",
    ")\n",
    "\n",
    "# Запуск поиска\n",
    "api.search(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    optimize_metric='accuracy',\n",
    "    total_walltime_limit=7200,\n",
    "    func_eval_time_limit_secs=600,\n",
    "    memory_limit=12288,  # 12 ГБ\n",
    "    n_jobs=1  # Обычно для трансформеров используется 1 процесс\n",
    ")\n",
    "\n",
    "# Получение результатов\n",
    "y_pred = api.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6451bcc-5bdd-4891-b9dd-e4d93433af79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression, Ridge, Lasso, ElasticNet,  # Для регрессии\n",
    "    LogisticRegression, SGDClassifier  # Для классификации\n",
    ")\n",
    "\n",
    "# Генерация данных для регрессии\n",
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Нормализация данных\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 1. Линейная регрессия\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "print(f\"Linear Regression R²: {r2_score(y_test, y_pred_lr)}\")\n",
    "print(f\"Linear Regression RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_lr))}\")\n",
    "\n",
    "# Визуализация коэффициентов\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(X.shape[1]), lr.coef_)\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.title('Linear Regression Coefficients')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Гребневая регрессия (Ridge)\n",
    "ridge = Ridge(alpha=1.0)  # alpha - параметр регуляризации\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "y_pred_ridge = ridge.predict(X_test_scaled)\n",
    "print(f\"Ridge Regression R²: {r2_score(y_test, y_pred_ridge)}\")\n",
    "\n",
    "# 3. Лассо регрессия \n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "y_pred_lasso = lasso.predict(X_test_scaled)\n",
    "print(f\"Lasso Regression R²: {r2_score(y_test, y_pred_lasso)}\")\n",
    "\n",
    "# 4. Elastic Net\n",
    "elastic = ElasticNet(alpha=0.1, l1_ratio=0.5)  # l1_ratio - баланс между L1 и L2\n",
    "elastic.fit(X_train_scaled, y_train)\n",
    "y_pred_elastic = elastic.predict(X_test_scaled)\n",
    "print(f\"ElasticNet R²: {r2_score(y_test, y_pred_elastic)}\")\n",
    "\n",
    "# Оптимизация гиперпараметров для Ridge с помощью GridSearchCV\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid_search = GridSearchCV(\n",
    "    Ridge(), \n",
    "    param_grid, \n",
    "    cv=5, \n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1\n",
    ")\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "print(f\"Best Ridge alpha: {grid_search.best_params_}\")\n",
    "print(f\"Best Ridge MSE: {-grid_search.best_score_}\")\n",
    "\n",
    "# Для классификации\n",
    "# ----------------\n",
    "# Генерация данных для классификации\n",
    "from sklearn.datasets import make_classification\n",
    "X_cls, y_cls = make_classification(\n",
    "    n_samples=1000, n_features=20, n_informative=10, \n",
    "    n_redundant=5, random_state=42\n",
    ")\n",
    "\n",
    "# Разделение данных\n",
    "X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(\n",
    "    X_cls, y_cls, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Нормализация\n",
    "X_train_cls_scaled = scaler.fit_transform(X_train_cls)\n",
    "X_test_cls_scaled = scaler.transform(X_test_cls)\n",
    "\n",
    "# 1. Логистическая регрессия\n",
    "logreg = LogisticRegression(\n",
    "    C=1.0,                  # Обратное к регуляризации\n",
    "    penalty='l2',           # Тип регуляризации (L2)\n",
    "    solver='liblinear',     # Алгоритм оптимизации\n",
    "    max_iter=1000,          # Максимальное число итераций\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_cls_scaled, y_train_cls)\n",
    "y_pred_logreg = logreg.predict(X_test_cls_scaled)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_score(y_test_cls, y_pred_logreg)}\")\n",
    "print(classification_report(y_test_cls, y_pred_logreg))\n",
    "\n",
    "# Вероятности для ROC-AUC\n",
    "y_proba_logreg = logreg.predict_proba(X_test_cls_scaled)[:, 1]\n",
    "\n",
    "# 2. SGD Classifier\n",
    "sgd_cls = SGDClassifier(\n",
    "    loss='log_loss',    # Функция потери (логистическая)\n",
    "    penalty='elasticnet',  # Регуляризация\n",
    "    alpha=0.0001,       # Сила регуляризации\n",
    "    l1_ratio=0.15,      # Соотношение L1/L2\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "sgd_cls.fit(X_train_cls_scaled, y_train_cls)\n",
    "y_pred_sgd = sgd_cls.predict(X_test_cls_scaled)\n",
    "print(f\"SGD Classifier Accuracy: {accuracy_score(y_test_cls, y_pred_sgd)}\")\n",
    "\n",
    "# Оптимизация гиперпараметров для логистической регрессии\n",
    "param_grid_logreg = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "grid_search_logreg = GridSearchCV(\n",
    "    LogisticRegression(random_state=42, max_iter=1000), \n",
    "    param_grid_logreg, \n",
    "    cv=5, \n",
    "    scoring='accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "grid_search_logreg.fit(X_train_cls_scaled, y_train_cls)\n",
    "print(f\"Best Logistic Regression params: {grid_search_logreg.best_params_}\")\n",
    "print(f\"Best Logistic Regression accuracy: {grid_search_logreg.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e83e5a3-0641-4828-8635-4e92a545e1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3426c00d-3fba-4211-bd11-2244680d05e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ce470f-a73e-415a-a013-c74aa1a53b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad400e-9e0b-41f4-bdf6-8e1847864097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340a496f-6c9b-4ac6-85a0-c7ba17214233",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
