{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fe58d65-50ae-46e4-b7c0-6ed99512763a",
   "metadata": {},
   "source": [
    "–û—Ç–ª–∏—á–Ω–æ, –¥–µ–ª–∞—é **–æ–¥–∏–Ω –±–æ–ª—å—à–æ–π —Ñ–∞–π–ª** –≤ —Ñ–æ—Ä–º–∞—Ç–µ *Markdown —Å HTML-–≤—Å—Ç–∞–≤–∫–∞–º–∏* ‚Äî —Ç–∞–∫ –µ–≥–æ –º–æ–∂–Ω–æ –≤—Å—Ç–∞–≤–∏—Ç—å –≤ `README.md`, –Ω–æ—É—Ç–±—É–∫ –∏–ª–∏ –ª—é–±—É—é Markdown-—Å—Ç—Ä–∞–Ω–∏—Ü—É.\n",
    "–ö–æ–¥ ‚Äî **—Ä–∞–±–æ—á–∏–π**, –æ–ø–∏—Å–∞–Ω–∏—è ‚Äî **–ø–æ–¥—Ä–æ–±–Ω—ã–µ (—É—Ä–æ–≤–µ–Ω—å PyTorch/TF)**. –•–æ—á–µ—à—å ‚Äî –ø—Ä–æ—Å—Ç–æ —É–¥–∞–ª—è–π HTML-–±–ª–æ–∫–∏ –∏ –æ—Å—Ç–∞—ë—Ç—Å—è —á–∏—Å—Ç—ã–π Python.\n",
    "\n",
    "---\n",
    "\n",
    "# `universal_competition_toolkit_MAXPRO.md`  (–≤—Å—Ç–∞–≤—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ü–µ–ª–∏–∫–æ–º)\n",
    "\n",
    "```markdown\n",
    "<!-- ============================== -->\n",
    "<!-- UNIVERSAL COMPETITION TOOLKIT -->\n",
    "<!-- MAX PRO ‚Äî –û–î–ò–ù –§–ê–ô–õ           -->\n",
    "<!-- ============================== -->\n",
    "\n",
    "<div style=\"padding:16px;border:1px solid #444;border-radius:10px;background:#0f0f0f;color:#eaeaea\">\n",
    "<h1>üéØ UNIVERSAL COMPETITION TOOLKIT ‚Äî MAX PRO (–û–¥–∏–Ω —Ñ–∞–π–ª)</h1>\n",
    "<p>\n",
    "–ì–æ—Ç–æ–≤—ã–π, —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π, <b>–±–æ–µ–≤–æ–π</b> –Ω–∞–±–æ—Ä –¥–ª—è —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–π (VSERO/FAIO/Kaggle/–ò–Ω—Ñ–æ–º–µ—Ç—Ä–∏–∫—Å).<br>\n",
    "–°–µ–∫—Ü–∏–∏ –∏–¥—É—Ç –≤ <b>–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–º –ø–æ—Ä—è–¥–∫–µ</b>: –æ—Ç –∏–º–ø–æ—Ä—Ç–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–æ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏, –æ–±—É—á–µ–Ω–∏—è –∏ —Å–∞–±–º–∏—Ç–æ–≤.<br>\n",
    "<b>–í—Å–µ –æ–ø–∏—Å–∞–Ω–∏—è –≤ HTML-–±–ª–æ–∫–∞—Ö</b> ‚Äî –∏—Ö –º–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å, –æ—Å—Ç–∞–≤–∏–≤ —Ç–æ–ª—å–∫–æ —Ä–∞–±–æ—á–∏–π –∫–æ–¥.\n",
    "</p>\n",
    "\n",
    "<ul>\n",
    "<li><a href=\"#sec1\">1. –ò–º–ø–æ—Ä—Ç—ã, —É—Ç–∏–ª–∏—Ç—ã, seed, –ª–æ–≥–≥–µ—Ä</a></li>\n",
    "<li><a href=\"#sec2\">2. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (CSV/JSON/Excel/Parquet/Pickle/Images/Audio)</a></li>\n",
    "<li><a href=\"#sec3\">3. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ (—á–∏—Å—Ç–∫–∞, —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è, –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è, n-–≥—Ä–∞–º–º—ã)</a></li>\n",
    "<li><a href=\"#sec4\">4. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (PIL/OpenCV/torchvision + –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏)</a></li>\n",
    "<li><a href=\"#sec5\">5. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ/—á–∏—Å–ª–æ–≤—ã–µ/—Å–∫–µ–π–ª–∏–Ω–≥)</a></li>\n",
    "<li><a href=\"#sec6\">6. –ë–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (LightGBM/XGBoost/CatBoost + Torch NN —Å–∫–µ–ª–µ—Ç)</a></li>\n",
    "<li><a href=\"#sec7\">7. –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ (SBERT/LaBSE/CLIP) –∏ —Ä–µ—Ç—Ä–∏–≤–ª</a></li>\n",
    "<li><a href=\"#sec8\">8. –°–∞–±–º–∏—Ç—ã (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è/—Ä–µ–≥—Ä–µ—Å—Å–∏—è/—Ç–µ–∫—Å—Ç)</a></li>\n",
    "<li><a href=\"#sec9\">9. –£—Ç–∏–ª–∏—Ç—ã (–ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ, –∫–æ–Ω—Ç—Ä–æ–ª—å –≤–µ—Ä—Å–∏–π)</a></li>\n",
    "</ul>\n",
    "</div>\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 1) –ò–º–ø–æ—Ä—Ç—ã, —É—Ç–∏–ª–∏—Ç—ã, seed, –ª–æ–≥–≥–µ—Ä <a id=\"sec1\"></a>\n",
    "\n",
    "```markdown\n",
    "<div style=\"border:1px solid #333;padding:14px;border-radius:8px;background:#111;color:#ddd\">\n",
    "<h2>üì¶ 1. –ò–º–ø–æ—Ä—Ç—ã (–º–∏–Ω–∏–º–∞–ª—å–Ω–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ)</h2>\n",
    "<p><b>–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ:</b> –±–∞–∑–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–ª—è –ª—é–±—ã—Ö –∑–∞–¥–∞—á: —Ñ–∞–π–ª–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞, –º–∞—Å—Å–∏–≤—ã/—Ç–∞–±–ª–∏—Ü—ã, —Ç–∏–ø—ã, –ª–æ–≥–∏.</p>\n",
    "<p><b>–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:</b> –≤—Å–µ–≥–¥–∞. –≠—Ç–æ —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç –ø–∞–π–ø–ª–∞–π–Ω–∞.</p>\n",
    "<p><b>–ì–¥–µ –ª–æ–º–∞–µ—Ç—Å—è –Ω–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞—Ö (VSERO):</b> –∏–Ω–æ–≥–¥–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –¥–æ–ø.–±–∏–±–ª–∏–æ—Ç–µ–∫–∏ (lightgbm/catboost/spacy). –°—Ç–∞–≤—å —É—Å–ª–æ–≤–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã.</p>\n",
    "</div>\n",
    "```\n",
    "\n",
    "```python\n",
    "import os, sys, json, math, random, shutil, warnings, pathlib, traceback, gc, time\n",
    "from glob import glob\n",
    "from typing import List, Dict, Any, Tuple, Optional, Iterable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"‚úîÔ∏è –ò–º–ø–æ—Ä—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")\n",
    "```\n",
    "\n",
    "```markdown\n",
    "<div style=\"border:1px solid #333;padding:14px;border-radius:8px;background:#0f0f0f;color:#ddd\">\n",
    "<h3>üìÅ –£—Ç–∏–ª–∏—Ç—ã –ø—É—Ç–µ–π</h3>\n",
    "<p>–ù–æ—Ä–º–∞–ª–∏–∑—É—é—Ç –ø—É—Ç–∏, —Å–æ–∑–¥–∞—é—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, —Å–æ–±–∏—Ä–∞—é—Ç —Å–ø–∏—Å–∫–∏ —Ñ–∞–π–ª–æ–≤ (–∫–∞—Ä—Ç–∏–Ω–æ–∫/–∞—É–¥–∏–æ). –û—Å–æ–±–µ–Ω–Ω–æ –ø–æ–ª–µ–∑–Ω–æ –Ω–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞—Ö, –≥–¥–µ —Ä–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –º–µ–Ω—è–µ—Ç—Å—è.</p>\n",
    "</div>\n",
    "```\n",
    "\n",
    "```python\n",
    "def ensure_dir(path: str) -> str:\n",
    "    p = pathlib.Path(path); p.mkdir(parents=True, exist_ok=True); return str(p)\n",
    "\n",
    "def norm_path(path: str) -> str:\n",
    "    return str(pathlib.Path(path).expanduser().resolve())\n",
    "\n",
    "def list_images(directory: str) -> List[str]:\n",
    "    exts = [\"*.png\",\"*.jpg\",\"*.jpeg\",\"*.bmp\",\"*.gif\",\"*.webp\"]\n",
    "    files=[]\n",
    "    for e in exts: files.extend(glob(os.path.join(directory, e)))\n",
    "    return sorted(files)\n",
    "\n",
    "def list_audio(directory: str) -> List[str]:\n",
    "    exts = [\"*.wav\",\"*.mp3\",\"*.ogg\",\"*.flac\",\"*.m4a\"]\n",
    "    files=[]\n",
    "    for e in exts: files.extend(glob(os.path.join(directory, e)))\n",
    "    return sorted(files)\n",
    "\n",
    "def file_size(path: str) -> str:\n",
    "    size = os.path.getsize(path); units = [\"B\",\"KB\",\"MB\",\"GB\",\"TB\"]\n",
    "    for u in units:\n",
    "        if size < 1024: return f\"{size:.2f}{u}\"\n",
    "        size /= 1024\n",
    "```\n",
    "\n",
    "```markdown\n",
    "<div style=\"border:1px solid #333;padding:14px;border-radius:8px;background:#0d0d0d;color:#ddd\">\n",
    "<h3>üé≤ Seed (—Ñ–∏–∫—Å–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å)</h3>\n",
    "<p><b>–ó–∞—á–µ–º:</b> –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ FAIO/VSERO/Kaggle.<br>\n",
    "<b>–ü–æ–¥–≤–æ–¥–Ω—ã–µ –∫–∞–º–Ω–∏:</b> –≤ torch –æ—Ç–∫–ª—é—á–∞–µ–º CUDNN benchmark –¥–ª—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏–∑–º–∞ (–º–æ–∂–µ—Ç –∑–∞–º–µ–¥–ª–∏—Ç—å).</p>\n",
    "</div>\n",
    "```\n",
    "\n",
    "```python\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    try:\n",
    "        import torch\n",
    "        torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    except Exception:\n",
    "        pass\n",
    "    print(f\"üîí Seed —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {seed}\")\n",
    "\n",
    "seed_everything(42)\n",
    "```\n",
    "\n",
    "```markdown\n",
    "<div style=\"border:1px solid #444;padding:14px;border-radius:8px;background:#101010;color:#ddd\">\n",
    "<h3>üß© –õ–æ–≥–≥–µ—Ä (—Ü–≤–µ—Ç–Ω–æ–π)</h3>\n",
    "<p>–ê–∫–∫—É—Ä–∞—Ç–Ω—ã–µ –ª–æ–≥–∏ —Å —Ç–∞–π–º—à—Ç–∞–º–ø–æ–º. –ß–µ–º —Å–ª–æ–∂–Ω–µ–µ –ø–∞–π–ø–ª–∞–π–Ω ‚Äî —Ç–µ–º –≤–∞–∂–Ω–µ–µ –ª–æ–≥–≥–µ—Ä.</p>\n",
    "<p><b>–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:</b> –º–æ–¥—É–ª—å <code>termcolor</code> –º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å. –ï—Å–ª–∏ –Ω–µ—Ç ‚Äî –¥–µ–ª–∞–µ–º graceful fallback.</p>\n",
    "</div>\n",
    "```\n",
    "\n",
    "```python\n",
    "import datetime\n",
    "try:\n",
    "    from termcolor import colored\n",
    "    def _c(text, color): return colored(text, color)\n",
    "except Exception:\n",
    "    def _c(text, color): return text\n",
    "\n",
    "class Log:\n",
    "    def __init__(self, logfile: Optional[str] = None):\n",
    "        self.logfile = logfile\n",
    "\n",
    "    def _write(self, line: str):\n",
    "        if self.logfile:\n",
    "            with open(self.logfile, \"a\", encoding=\"utf-8\") as f: f.write(line+\"\\n\")\n",
    "\n",
    "    def _ts(self): return datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    def info(self, msg: str):    line=f\"[{self._ts()}] [INFO] {msg}\";    print(_c(line,\"cyan\"));    self._write(line)\n",
    "    def success(self, msg: str): line=f\"[{self._ts()}] [OK] {msg}\";      print(_c(line,\"green\"));   self._write(line)\n",
    "    def warn(self, msg: str):    line=f\"[{self._ts()}] [WARN] {msg}\";    print(_c(line,\"yellow\"));  self._write(line)\n",
    "    def error(self, msg: str):   line=f\"[{self._ts()}] [ERR] {msg}\";     print(_c(line,\"red\"));     self._write(line)\n",
    "\n",
    "logger = Log()\n",
    "logger.success(\"–õ–æ–≥–≥–µ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2) –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (CSV/JSON/Excel/Parquet/Pickle/Images/Audio) <a id=\"sec2\"></a>\n",
    "\n",
    "```markdown\n",
    "<div style=\"border:1px solid #333;padding:14px;border-radius:8px;background:#0f0f0f;color:#ddd\">\n",
    "<h2>üì• 2. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö</h2>\n",
    "<p><b>–¶–µ–ª—å:</b> –µ–¥–∏–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –≤—Å–µ—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤. –ö–æ–¥ –ø–∏—à–µ—Ç –ª–æ–≥–∏, –ª–æ–≤–∏—Ç —á–∞—Å—Ç—ã–µ –æ—à–∏–±–∫–∏ –∏ –¥–∞—ë—Ç —Å–æ–≤–µ—Ç—ã (–æ—Å–æ–±–µ–Ω–Ω–æ –¥–ª—è VSERO/FAIO –∫–ª–∞—Å—Ç–µ—Ä–æ–≤).</p>\n",
    "<p><b>–ö–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã:</b> –∫–æ–≥–¥–∞ <code>read_csv</code> –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–µ–ª—å–∑—è; —É—Å–∫–æ—Ä–µ–Ω–∏–µ —á—Ç–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤; Parquet –Ω–∞ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è—Ö; –∏–∑–±–µ–≥–∞–µ–º UTF-8 –æ—à–∏–±–æ–∫; –ø–∞–∫–µ—Ç–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.</p>\n",
    "</div>\n",
    "```\n",
    "\n",
    "### 2.1 CSV / JSON / Excel / Parquet / Pickle\n",
    "\n",
    "```python\n",
    "def load_csv(path: str, low_memory: bool = True, encoding: Optional[str] = \"utf-8\",\n",
    "             sep: str = \",\", nrows: Optional[int] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    –ë—ã—Å—Ç—Ä–∞—è –∏ –±–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ CSV.\n",
    "    –°–æ–≤–µ—Ç—ã:\n",
    "    - –ï—Å–ª–∏ 'utf-8' –ø–∞–¥–∞–µ—Ç: –ø–æ–ø—Ä–æ–±—É–π encoding='utf-8-sig' –∏–ª–∏ 'cp1251'\n",
    "    - –î–ª—è –æ–≥—Ä–æ–º–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: —É–∫–∞–∂–∏ dtype —Å—Ç–æ–ª–±—Ü–æ–≤, usecols, nrows\n",
    "    - –ù–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞—Ö: low_memory=True —Å–Ω–∏–∂–∞–µ—Ç RAM, –Ω–æ —Ç–∏–ø—ã –º–æ–≥—É—Ç —Å—Ç–∞—Ç—å 'object'\n",
    "    \"\"\"\n",
    "    logger.info(f\"–ß–∏—Ç–∞—é CSV: {path}\")\n",
    "    try:\n",
    "        df = pd.read_csv(path, sep=sep, encoding=encoding, low_memory=low_memory, nrows=nrows)\n",
    "        logger.success(f\"CSV OK: shape={df.shape}\")\n",
    "        return df\n",
    "    except UnicodeDecodeError as e:\n",
    "        logger.warn(\"UnicodeDecodeError ‚Üí –ø—Ä–æ–±—É—é 'utf-8-sig'\")\n",
    "        try:\n",
    "            df = pd.read_csv(path, sep=sep, encoding=\"utf-8-sig\", low_memory=low_memory, nrows=nrows)\n",
    "            logger.success(f\"CSV OK (utf-8-sig): shape={df.shape}\")\n",
    "            return df\n",
    "        except Exception as e2:\n",
    "            logger.error(f\"–ü—Ä–æ–±–ª–µ–º–∞ —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π: {e2}\")\n",
    "            raise\n",
    "    except pd.errors.ParserError as e:\n",
    "        logger.warn(\"ParserError: —É–∫–∞–∂–∏ sep=';' –∏–ª–∏ engine='python'\")\n",
    "        df = pd.read_csv(path, sep=sep, encoding=encoding, low_memory=low_memory,\n",
    "                         engine=\"python\", nrows=nrows)\n",
    "        logger.success(f\"CSV OK (engine=python): shape={df.shape}\")\n",
    "        return df\n",
    "\n",
    "def load_json(path: str, lines: bool = False) -> Any:\n",
    "    \"\"\"\n",
    "    JSON:\n",
    "    - lines=True –¥–ª—è JSONL (–ø–æ —Å—Ç—Ä–æ–∫–µ –Ω–∞ –æ–±—ä–µ–∫—Ç)\n",
    "    - –∏–Ω–∞—á–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π JSON\n",
    "    \"\"\"\n",
    "    logger.info(f\"–ß–∏—Ç–∞—é JSON: {path} (lines={lines})\")\n",
    "    if lines:\n",
    "        return pd.read_json(path, lines=True)\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def load_excel(path: str, sheet_name: Optional[str] = None) -> pd.DataFrame:\n",
    "    logger.info(f\"–ß–∏—Ç–∞—é Excel: {path} sheet={sheet_name or '(–ø–µ—Ä–≤—ã–π)'}\")\n",
    "    return pd.read_excel(path, sheet_name=sheet_name)\n",
    "\n",
    "def load_parquet(path: str, columns: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parquet:\n",
    "    - –±—ã—Å—Ç—Ä–µ–µ –∏ –∫–æ–º–ø–∞–∫—Ç–Ω–µ–µ CSV\n",
    "    - –Ω–∞ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è—Ö, –µ—Å–ª–∏ –¥–∞—é—Ç parquet ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π –µ–≥–æ, —ç–∫–æ–Ω–æ–º–∏—Ç –≤—Ä–µ–º—è\n",
    "    \"\"\"\n",
    "    logger.info(f\"–ß–∏—Ç–∞—é Parquet: {path} cols={columns}\")\n",
    "    return pd.read_parquet(path, columns=columns)\n",
    "\n",
    "def load_pickle(path: str) -> Any:\n",
    "    logger.info(f\"–ß–∏—Ç–∞—é Pickle: {path}\")\n",
    "    import pickle\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "```\n",
    "\n",
    "```markdown\n",
    "<div style=\"border:1px solid #444;padding:14px;border-radius:8px;background:#121212;color:#ddd\">\n",
    "<h4>‚ö†Ô∏è –ö–æ–≥–¥–∞ <code>read_csv</code> –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–µ–ª—å–∑—è</h4>\n",
    "<ul>\n",
    "<li>–§–∞–π–ª –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π (5‚Äì20 –ì–ë) ‚Üí —Ä–∞–∑–æ—Ä–≤—ë—Ç RAM. –õ—É—á—à–µ <b>—á–∏—Ç–∞—Ç—å –ø–æ —á–∞—Å—Ç—è–º</b> (chunksize) –∏–ª–∏ –ø–µ—Ä–µ–π—Ç–∏ –Ω–∞ Parquet.</li>\n",
    "<li>–°–ª–æ–∂–Ω—ã–µ —Ç–∏–ø—ã (—Å–ø–∏—Å–∫–∏/—Å–ª–æ–≤–∞—Ä–∏–∫–∏ –≤–Ω—É—Ç—Ä–∏ —è—á–µ–µ–∫) ‚Üí —É–¥–æ–±–Ω–µ–µ JSONL (lines=True) –∏–ª–∏ Pickle.</li>\n",
    "<li>–ù–µ—Å—Ç–∞–±–∏–ª—å–Ω–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞ (–º–Ω–æ–≥–æ —Å–º–µ—à–∞–Ω–Ω—ã—Ö –∫–æ–¥–∏—Ä–æ–≤–æ–∫) ‚Üí —Å–Ω–∞—á–∞–ª–∞ –Ω–æ—Ä–º–∞–ª–∏–∑—É–π (iconv, recode), –ª–∏–±–æ —á–∏—Ç–∞–π –¥–≤–æ–∏—á–Ω–æ, —á–∏—Å—Ç–∏, –ø–æ—Ç–æ–º –ø–∞—Ä—Å—å.</li>\n",
    "</ul>\n",
    "\n",
    "<h4>üí° –£—Å–∫–æ—Ä–µ–Ω–∏–µ —á—Ç–µ–Ω–∏—è –±–æ–ª—å—à–∏—Ö CSV</h4>\n",
    "<ul>\n",
    "<li><code>usecols</code>: –≤—ã–±–∏—Ä–∞–π —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏</li>\n",
    "<li><code>dtype</code>: —Å—Ä–∞–∑—É —É–∫–∞–∂–∏ —Ç–∏–ø—ã —Å—Ç–æ–ª–±—Ü–æ–≤</li>\n",
    "<li><code>chunksize</code>: —á–∏—Ç–∞–π –∫—É—Å–∫–∞–º–∏ –∏ –∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä—É–π</li>\n",
    "<li>–ï—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω Parquet ‚Üí –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–π –æ–¥–∏–Ω —Ä–∞–∑ –∏ —á–∏—Ç–∞–π Parquet –¥–∞–ª—å—à–µ</li>\n",
    "</ul>\n",
    "\n",
    "<pre><code># –ø—Ä–∏–º–µ—Ä —á—Ç–µ–Ω–∏—è –ø–æ —á–∞—Å—Ç—è–º\n",
    "chunks = []\n",
    "for chunk in pd.read_csv(\"huge.csv\", chunksize=200_000, usecols=[\"id\",\"text\",\"label\"]):\n",
    "    # –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–π chunk –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏\n",
    "    chunks.append(chunk)\n",
    "df = pd.concat(chunks, ignore_index=True)\n",
    "</code></pre>\n",
    "\n",
    "<h4>üßØ –ö–∞–∫ –∏–∑–±–µ–∂–∞—Ç—å UTF-8 –æ—à–∏–±–æ–∫</h4>\n",
    "<p>–ï—Å–ª–∏ –ø–∞–¥–∞–µ—Ç –Ω–∞ <code>utf-8</code>: –ø–æ–ø—Ä–æ–±—É–π <code>utf-8-sig</code>, –¥–∞–ª–µ–µ <code>cp1251</code>. –ï—Å–ª–∏ –≤—Å—ë –ø–ª–æ—Ö–æ ‚Äî –æ—Ç–∫—Ä–æ–π –≤ –±–∏–Ω–∞—Ä–Ω–æ–º —Ä–µ–∂–∏–º–µ, –ø–æ—Å–º–æ—Ç—Ä–∏ –ø–µ—Ä–≤—ã–µ –±–∞–π—Ç—ã, –æ–ø—Ä–µ–¥–µ–ª–∏ BOM.</p>\n",
    "\n",
    "<h4>üèÅ Parquet –Ω–∞ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è—Ö</h4>\n",
    "<p>–ì–¥–µ –¥–æ—Å—Ç—É–ø–Ω–æ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º Parquet: –±—ã—Å—Ç—Ä–µ–µ —á—Ç–µ–Ω–∏–µ/–∑–∞–ø–∏—Å—å, –º–µ–Ω—å—à–µ I/O. –ù–∞ VSERO –∫–ª–∞—Å—Ç–µ—Ä —á–∞—Å—Ç–æ —ç—Ç–æ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ —Å–æ–∫—Ä–∞—â–∞–µ—Ç –≤—Ä–µ–º—è.</p>\n",
    "</div>\n",
    "```\n",
    "\n",
    "### 2.2 –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (PIL/OpenCV/torchvision) + –ø–∞–∫–µ—Ç–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞\n",
    "\n",
    "```python\n",
    "from PIL import Image\n",
    "\n",
    "def load_image_pil(path: str, mode: str = \"RGB\") -> Image.Image:\n",
    "    \"\"\"\n",
    "    –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∏ —á–µ—Ä–µ–∑ PIL.\n",
    "    mode='RGB' –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç 3 –∫–∞–Ω–∞–ª–∞.\n",
    "    \"\"\"\n",
    "    img = Image.open(path)\n",
    "    if mode: img = img.convert(mode)\n",
    "    return img\n",
    "\n",
    "def load_image_cv2(path: str, to_rgb: bool = True):\n",
    "    \"\"\"\n",
    "    cv2.imread ‚Üí BGR; –µ—Å–ª–∏ to_rgb=True, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫ RGB.\n",
    "    cv2 –±—ã—Å—Ç—Ä–µ–µ –Ω–∞ –º–Ω–æ–≥–∏—Ö –∫–ª–∞—Å—Ç–µ—Ä–∞—Ö, –Ω–æ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Å–±–æ—Ä–∫–∏.\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    im = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    if im is None:\n",
    "        raise FileNotFoundError(f\"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å: {path}\")\n",
    "    if to_rgb and len(im.shape) == 3:\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    return im\n",
    "\n",
    "def iter_image_batches(paths: List[str], batch_size: int = 32, loader=\"pil\"):\n",
    "    \"\"\"\n",
    "    –ü–∞–∫–µ—Ç–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ‚Äî —á—Ç–æ–±—ã –Ω–µ —Å—ä–µ–¥–∞—Ç—å –≤—Å—é RAM.\n",
    "    loader: 'pil' | 'cv2'\n",
    "    \"\"\"\n",
    "    assert loader in (\"pil\",\"cv2\")\n",
    "    for i in range(0, len(paths), batch_size):\n",
    "        batch_paths = paths[i:i+batch_size]\n",
    "        batch=[]\n",
    "        for p in batch_paths:\n",
    "            try:\n",
    "                if loader==\"pil\":\n",
    "                    batch.append(load_image_pil(p, mode=\"RGB\"))\n",
    "                else:\n",
    "                    batch.append(load_image_cv2(p, to_rgb=True))\n",
    "            except Exception as e:\n",
    "                logger.warn(f\"–ü—Ä–æ–ø—É—Å–∫–∞—é {p}: {e}\")\n",
    "        yield batch_paths, batch\n",
    "```\n",
    "\n",
    "```markdown\n",
    "<div style=\"border:1px solid #444;padding:14px;border-radius:8px;background:#121212;color:#ddd\">\n",
    "<h4>üß† –ö–∞–∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–∞—Ä—Ç–∏—è–º–∏</h4>\n",
    "<ul>\n",
    "<li>–ù–µ –∑–∞–≥—Ä—É–∂–∞–π —Å—Ä–∞–∑—É –≤—Å–µ 100k –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ‚Äî –≤—ã–±—å–µ—Ç –ø–∞–º—è—Ç—å.</li>\n",
    "<li>–ò—Å–ø–æ–ª—å–∑—É–π <code>iter_image_batches</code> –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–π –ø–æ 32‚Äì128 –∫–∞—Ä—Ç–∏–Ω–æ–∫.</li>\n",
    "<li>–ó–∞–∫—Ä—ã–≤–∞–π –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ã (–¥–ª—è PIL –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —É–±—Ä–∞—Ç—å —Å—Å—ã–ª–∫–∏, –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –¥–µ–ª–∞–π <code>gc.collect()</code>).</li>\n",
    "</ul>\n",
    "\n",
    "<h4>‚è© –£—Å–∫–æ—Ä–µ–Ω–∏–µ</h4>\n",
    "<ul>\n",
    "<li>cv2 –æ–±—ã—á–Ω–æ –±—ã—Å—Ç—Ä–µ–µ, –Ω–æ —É–±–µ–¥–∏—Å—å –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –∫–∞–Ω–∞–ª–æ–≤ (BGR‚ÜíRGB)</li>\n",
    "<li>–•—Ä–∞–Ω–∏ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è (–∫–µ—à) –ø—Ä–∏ –¥–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞—Ö</li>\n",
    "</ul>\n",
    "</div>\n",
    "```\n",
    "\n",
    "### 2.3 –ê—É–¥–∏–æ (librosa)\n",
    "\n",
    "```python\n",
    "def load_audio(path: str, sr: Optional[int] = None):\n",
    "    \"\"\"\n",
    "    –ß–∏—Ç–∞–µ—Ç –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ librosa. –ï—Å–ª–∏ sr=None ‚Äî —Ä–æ–¥–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞.\n",
    "    –ü–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è: pip install librosa (–º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –Ω–∞ –∫–ª–∞—Å—Ç–µ—Ä–µ)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import librosa\n",
    "    except Exception as e:\n",
    "        logger.error(\"librosa –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏ –∏–ª–∏ –æ—Ç–∫–ª—é—á–∏ –∞—É–¥–∏–æ.\")\n",
    "        raise\n",
    "    y, current_sr = librosa.load(path, sr=sr, mono=True)\n",
    "    return y, (sr or current_sr)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3) –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ <a id=\"sec3\"></a>\n",
    "\n",
    "```markdown\n",
    "<div style=\"border:1px solid #333;padding:14px;border-radius:8px;background:#0f0f0f;color:#ddd\">\n",
    "<h2>üìù 3. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞</h2>\n",
    "<p>–ß–∏—Å—Ç–∫–∞, —É–Ω–∏—Ñ–∏–∫–∞—Ü–∏—è, —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è, –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è. –î–µ–ª–∞–π –º–∏–Ω–∏–º—É–º –Ω–∞ —Å—Ç–∞—Ä—Ç–µ: lower/trim/–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è unicode.</p>\n",
    "<p><b>–ù–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞—Ö:</b> NLTK/spaCy –º–æ–¥–µ–ª–∏ –º–æ–≥—É—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å. –ò—Å–ø–æ–ª—å–∑—É–π try/except –∏ degrade gracefully.</p>\n",
    "</div>\n",
    "```\n",
    "\n",
    "```python\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def text_basic_clean(s: Any) -> str:\n",
    "    if not isinstance(s, str): return \"\"\n",
    "    s = s.strip()\n",
    "    s = unicodedata.normalize(\"NFKC\", s)   # unicode –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "    s = s.replace(\"\\u200b\",\"\")             # zero-width space\n",
    "    s = re.sub(r\"\\s+\", \" \", s)             # –º—É–ª—å—Ç–∏-–ø—Ä–æ–±–µ–ª—ã -> –æ–¥–∏–Ω\n",
    "    return s.lower()\n",
    "\n",
    "def clean_text_column(df: pd.DataFrame, col: str, new_col: Optional[str] = None) -> pd.DataFrame:\n",
    "    new_col = new_col or (col + \"_clean\")\n",
    "    df[new_col] = df[col].apply(text_basic_clean)\n",
    "    return df\n",
    "```\n",
    "\n",
    "```markdown\n",
    "<div style=\"border:1px solid #444;padding:14px;border-radius:8px;background:#121212;color:#ddd\">\n",
    "<h4>üî§ –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è / –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è (NLTK/spaCy)</h4>\n",
    "<p>–ò—Å–ø–æ–ª—å–∑—É–π, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ. –ï—Å–ª–∏ –Ω–µ—Ç ‚Äî –ø–∞–¥–∞–π –Ω–∞ –±–∞–∑–æ–≤—É—é —á–∏—Å—Ç–∫—É.</p>\n",
    "</div>\n",
    "```\n",
    "\n",
    "```python\n",
    "def try_spacy_lemmatize(texts: List[str], lang: str = \"ru\"):\n",
    "    \"\"\"\n",
    "    –ü—ã—Ç–∞–µ–º—Å—è –ª–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å —á–µ—Ä–µ–∑ spaCy. –ï—Å–ª–∏ –º–æ–¥–µ–ª–∏ –Ω–µ—Ç ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Å–ø–∏—Å–æ–∫.\n",
    "    –¢—Ä–µ–±—É–µ—Ç—Å—è: python -m spacy download ru_core_news_sm (–∏–ª–∏ en_core_web_sm)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import spacy\n",
    "        if lang == \"ru\":\n",
    "            nlp = spacy.load(\"ru_core_news_sm\")\n",
    "        elif lang == \"en\":\n",
    "            nlp = spacy.load(\"en_core_web_sm\")\n",
    "        else:\n",
    "            return texts\n",
    "        out=[]\n",
    "        for doc in nlp.pipe(texts, batch_size=256, disable=[\"ner\",\"parser\"]):\n",
    "            out.append(\" \".join([t.lemma_ for t in doc]))\n",
    "        return out\n",
    "    except Exception as e:\n",
    "        logger.warn(f\"spaCy –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}\")\n",
    "        return texts\n",
    "\n",
    "def try_nltk_tokenize(text: str) -> List[str]:\n",
    "    try:\n",
    "        import nltk\n",
    "        from nltk.tokenize import word_tokenize\n",
    "        # nltk.download('punkt') # –æ–¥–Ω–∞–∂–¥—ã –Ω–∞ –º–∞—à–∏–Ω–µ —Å —Å–µ—Ç—å—é\n",
    "        return word_tokenize(text)\n",
    "    except Exception:\n",
    "        return text.split()\n",
    "```\n",
    "\n",
    "```markdown\n",
    "<div style=\"border:1px solid #444;padding:14px;border-radius:8px;background:#121212;color:#ddd\">\n",
    "<h4>üìå N-–≥—Ä–∞–º–º—ã (—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —à–∞–±–ª–æ–Ω)</h4>\n",
    "<p>–ü—Ä–∏–º–µ–Ω–∏–º –∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏, TF-IDF, –±–∞–∑–æ–≤—ã–º –º–æ–¥–µ–ª—è–º.</p>\n",
    "</div>\n",
    "```\n",
    "\n",
    "```python\n",
    "from collections import Counter\n",
    "\n",
    "def generate_ngrams(tokens: List[str], n: int = 2) -> List[Tuple[str,...]]:\n",
    "    return [tuple(tokens[i:i+n]) for i in range(0, max(0, len(tokens)-n+1))]\n",
    "\n",
    "def top_ngrams(texts: Iterable[str], n: int = 2, top_k: int = 20) -> List[Tuple[Tuple[str,...], int]]:\n",
    "    cnt = Counter()\n",
    "    for s in texts:\n",
    "        toks = try_nltk_tokenize(text_basic_clean(s))\n",
    "        for g in generate_ngrams(toks, n=n): cnt[g]+=1\n",
    "    return cnt.most_common(top_k)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 4) –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (PIL/OpenCV/torchvision + –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏) <a id=\"sec4\"></a>\n",
    "\n",
    "```markdown\n",
    "<div style=\"border:1px solid #333;padding:14px;border-radius:8px;background:#0f0f0f;color:#ddd\">\n",
    "<h2>üñºÔ∏è 4. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π</h2>\n",
    "<p>–®–∞–±–ª–æ–Ω—ã –¥–ª—è baseline: resize, —Ü–µ–Ω—Ç—Ä/—Ä–∞–Ω–¥–æ–º –∫—Ä–æ–ø—ã, –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è, –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏.</p>\n",
    "<p><b>–ó–∞–º–µ—á–∞–Ω–∏–µ:</b> torchvision –º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –Ω–∞ –∫–ª–∞—Å—Ç–µ—Ä–µ. –î–µ–ª–∞–µ–º try/except –∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã (PIL/cv2).</p>\n",
    "</div>\n",
    "```\n",
    "\n",
    "```python\n",
    "# torchvision-–ø–∞–π–ø–ª–∞–π–Ω (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)\n",
    "try:\n",
    "    import torch\n",
    "    from torchvision import transforms\n",
    "\n",
    "    def get_torchvision_train_transforms(img_size: int = 224):\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomResizedCrop(img_size, scale=(0.8,1.0)),\n",
    "            transforms.ToTensor(),\n",
    "            # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–¥ ImageNet\n",
    "            transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "        ])\n",
    "\n",
    "    def get_torchvision_valid_transforms(img_size: int = 224):\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.CenterCrop(img_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
    "        ])\n",
    "except Exception as e:\n",
    "    logger.warn(f\"torchvision –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}\")\n",
    "    torch = None\n",
    "```\n",
    "\n",
    "```python\n",
    "# –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –Ω–∞ PIL/cv2 (–º–∏–Ω–∏–º—É–º)\n",
    "def pil_resize(img: Image.Image, size: Tuple[int,int]=(224,224)) -> Image.Image:\n",
    "    return img.resize(size, Image.BILINEAR)\n",
    "\n",
    "def cv2_resize(im, size: Tuple[int,int]=(224,224)):\n",
    "    import cv2\n",
    "    return cv2.resize(im, size, interpolation=cv2.INTER_LINEAR)\n",
    "```\n",
    "\n",
    "```markdown\n",
    "<div style=\"border:1px solid #444;padding:14px;border-radius:8px;background:#121212;color:#ddd\">\n",
    "<h4>üí° –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏</h4>\n",
    "<ul>\n",
    "<li><b>–õ—ë–≥–∫–∏–µ</b>: flip, crop, color jitter (–µ—Å–ª–∏ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä)</li>\n",
    "<li><b>–û—Å—Ç–æ—Ä–æ–∂–Ω–æ</b> —Å —Å–∏–ª—å–Ω—ã–º–∏ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è–º–∏ (mixup/cutout) –Ω–∞ –º–∞–ª–µ–Ω—å–∫–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö ‚Äî –ª–µ–≥–∫–æ –ø–µ—Ä–µ—É—Å–µ—Ä–¥—Å—Ç–≤–æ–≤–∞—Ç—å</li>\n",
    "</ul>\n",
    "</div>\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5) –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö <a id=\"sec5\"></a>\n",
    "\n",
    "```markdown\n",
    "<div style=\"border:1px solid #333;padding:14px;border-radius:8px;background:#0f0f0f;color:#ddd\">\n",
    "<h2>üìä 5. –¢–∞–±–ª–∏—á–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏</h2>\n",
    "<p>–°–∫–µ–π–ª–∏–Ω–≥, one-hot, –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤, label encoding. –°–æ–≤–º–µ—Å—Ç–∏–º–æ —Å–æ sklearn/LightGBM/CatBoost.</p>\n",
    "</div>\n",
    "```\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def split_train_val(df: pd.DataFrame, target: str, test_size: float=0.2, random_state: int=42):\n",
    "    X = df.drop(columns=[target]); y = df[target]\n",
    "    Xtr, Xva, ytr, yva = train_test_split(X, y, test_size=test_size, random_state=random_state, shuffle=True, stratify=None)\n",
    "    return Xtr, Xva, ytr, yva\n",
    "\n",
    "def build_preprocessor(numeric_cols: List[str], cat_cols: List[str], scale: str=\"standard\"):\n",
    "    scaler = StandardScaler() if scale==\"standard\" else MinMaxScaler()\n",
    "    cat = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", scaler, numeric_cols),\n",
    "            (\"cat\", cat, cat_cols)\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 6) –ë–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (LightGBM/XGBoost/CatBoost + Torch NN —Å–∫–µ–ª–µ—Ç) <a id=\"sec6\"></a>\n",
    "\n",
    "```markdown\n",
    "<div style=\"border:1px solid #333;padding:14px;border-radius:8px;background:#0f0f0f;color:#ddd\">\n",
    "<h2>ü§ñ 6. –ë–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏</h2>\n",
    "<p>–ë—ã—Å—Ç—Ä—ã–µ –±—ç–π—Å–ª–∞–π–Ω—ã –¥–ª—è —Ç–∞–±–ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö + —Å–∫–µ–ª–µ—Ç Torch-—Å–µ—Ç–∏ –¥–ª—è –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –∑–∞–¥–∞—á.</p>\n",
    "<p><b>–ù–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞—Ö:</b> –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –±—É—Å—Ç–∏–Ω–≥–æ–≤ –º–æ–≥—É—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å ‚Äî –¥–µ–ª–∞–π try/except –∏ graceful degrade.</p>\n",
    "</div>\n",
    "```\n",
    "\n",
    "```python\n",
    "# LightGBM\n",
    "def train_lgbm(Xtr, ytr, Xva, yva, params: Optional[Dict[str,Any]] = None):\n",
    "    try:\n",
    "        import lightgbm as lgb\n",
    "    except Exception as e:\n",
    "        logger.error(\"LightGBM –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\"); raise\n",
    "    params = params or dict(\n",
    "        objective=\"regression\",\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        feature_fraction=0.9,\n",
    "        bagging_fraction=0.8,\n",
    "        bagging_freq=1,\n",
    "        metric=\"rmse\",\n",
    "        n_estimators=2000\n",
    "    )\n",
    "    model = lgb.LGBMModel(**params)\n",
    "    model.fit(Xtr, ytr, eval_set=[(Xva, yva)], eval_metric=\"rmse\",\n",
    "              callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)])\n",
    "    return model\n",
    "\n",
    "# XGBoost\n",
    "def train_xgb(Xtr, ytr, Xva, yva, params: Optional[Dict[str,Any]] = None):\n",
    "    try:\n",
    "        import xgboost as xgb\n",
    "    except Exception as e:\n",
    "        logger.error(\"XGBoost –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\"); raise\n",
    "    params = params or dict(\n",
    "        objective=\"reg:squarederror\",\n",
    "        eta=0.05,\n",
    "        max_depth=8,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        n_estimators=2000,\n",
    "        tree_method=\"hist\"\n",
    "    )\n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    model.fit(Xtr, ytr, eval_set=[(Xva, yva)], eval_metric=\"rmse\", verbose=False)\n",
    "    return model\n",
    "\n",
    "# CatBoost\n",
    "def train_cat(Xtr, ytr, Xva, yva, params: Optional[Dict[str,Any]] = None):\n",
    "    try:\n",
    "        from catboost import CatBoostRegressor\n",
    "    except Exception as e:\n",
    "        logger.error(\"CatBoost –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\"); raise\n",
    "    params = params or dict(\n",
    "        loss_function=\"RMSE\",\n",
    "        learning_rate=0.05,\n",
    "        depth=8,\n",
    "        iterations=5000,\n",
    "        od_type=\"Iter\",\n",
    "        od_wait=200,\n",
    "        verbose=False\n",
    "    )\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(Xtr, ytr, eval_set=(Xva, yva), use_best_model=True)\n",
    "    return model\n",
    "```\n",
    "\n",
    "```python\n",
    "# Torch NN (—Å–∫–µ–ª–µ—Ç)\n",
    "def build_torch_mlp(input_dim: int, hidden: int = 256, out_dim: int = 1):\n",
    "    try:\n",
    "        import torch\n",
    "        import torch.nn as nn\n",
    "    except Exception as e:\n",
    "        logger.error(\"PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\"); raise\n",
    "\n",
    "    class MLP(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(input_dim, hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(hidden, hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(hidden, out_dim)\n",
    "            )\n",
    "        def forward(self, x): return self.net(x)\n",
    "    return MLP()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 7) –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ —Ä–µ—Ç—Ä–∏–≤–ª (SBERT/LaBSE/CLIP) <a id=\"sec7\"></a>\n",
    "\n",
    "```markdown\n",
    "<div style=\"border:1px solid #333;padding:14px;border-radius:8px;background:#0f0f0f;color:#ddd\">\n",
    "<h2>üß† 7. –≠–º–±–µ–¥–¥–∏–Ω–≥–∏</h2>\n",
    "<p>–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ –∑–∞–≥–æ—Ç–æ–≤–∫–∏ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Ç–µ–∫—Å—Ç–∞/–∫–∞—Ä—Ç–∏–Ω–æ–∫ –∏ –ø—Ä–æ—Å—Ç–æ–≥–æ –ø–æ–∏—Å–∫–∞ –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π.</p>\n",
    "<p><b>–ù–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞—Ö:</b> –º–æ–¥–µ–ª—å–∫–∏ –∏–∑ <code>sentence-transformers</code> –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –æ—Ñ—Ñ–ª–∞–π–Ω. –ì–æ—Ç–æ–≤—å –ª–æ–∫–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞ –∑–∞—Ä–∞–Ω–µ–µ.</p>\n",
    "</div>\n",
    "```\n",
    "\n",
    "```python\n",
    "def sbert_encode(texts: List[str], model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "                 batch_size: int = 64) -> np.ndarray:\n",
    "    try:\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "    except Exception as e:\n",
    "        logger.error(\"sentence-transformers –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\"); raise\n",
    "    model = SentenceTransformer(model_name)\n",
    "    embs = model.encode(texts, batch_size=batch_size, convert_to_numpy=True, show_progress_bar=False, normalize_embeddings=True)\n",
    "    return embs\n",
    "\n",
    "def cosine_search(query_vec: np.ndarray, index_vecs: np.ndarray, top_k: int = 5) -> List[Tuple[int,float]]:\n",
    "    # –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∫–æ—Å–∏–Ω—É—Å—ã ‚Üí arg top-k\n",
    "    sims = index_vecs @ query_vec\n",
    "    idx = np.argpartition(-sims, top_k)[:top_k]\n",
    "    idx = idx[np.argsort(-sims[idx])]\n",
    "    return [(int(i), float(sims[i])) for i in idx]\n",
    "```\n",
    "\n",
    "```markdown\n",
    "<div style=\"border:1px solid #444;padding:14px;border-radius:8px;background:#121212;color:#ddd\">\n",
    "<h4>üñºÔ∏è CLIP (zero-shot)</h4>\n",
    "<p>–ï—Å–ª–∏ –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫ OpenAI CLIP (–∏–ª–∏ open-clip) –æ—Ñ—Ñ–ª–∞–π–Ω ‚Äî –º–æ–∂–Ω–æ –¥–µ–ª–∞—Ç—å zero-shot –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é —á–µ—Ä–µ–∑ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø—Ä–æ–º–ø—Ç—ã.</p>\n",
    "</div>\n",
    "```\n",
    "\n",
    "```python\n",
    "def clip_zero_shot_scores(images: List[Image.Image], texts: List[str], model_name: str = \"ViT-B-32\"):\n",
    "    \"\"\"\n",
    "    –ó–∞–≥–æ—Ç–æ–≤–∫–∞: –∏—Å–ø–æ–ª—å–∑—É–π open-clip / clip –ø–æ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏.\n",
    "    –î–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏ —Ç—É—Ç —Ç–æ–ª—å–∫–æ —Å—Ö–µ–º–∞ ‚Äî –ø–æ–¥–∫–ª—é—á–∞–π —Ä–µ–∞–ª—å–Ω—É—é –ª–∏–±—É –Ω–∞ —Å–≤–æ–µ–π –º–∞—à–∏–Ω–µ.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import torch\n",
    "        import clip  # openai/clip\n",
    "    except Exception as e:\n",
    "        logger.warn(\"CLIP –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–¥–∫–ª—é—á–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫—É –∏ –≤–µ—Å–∞ –ª–æ–∫–∞–ª—å–Ω–æ.\")\n",
    "        return None\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model, preprocess = clip.load(model_name, device=device)\n",
    "    with torch.no_grad():\n",
    "        image_t = torch.stack([preprocess(im) for im in images]).to(device)\n",
    "        text_t = clip.tokenize(texts).to(device)\n",
    "        image_features = model.encode_image(image_t)\n",
    "        text_features  = model.encode_text(text_t)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        text_features  /= text_features.norm(dim=-1, keepdim=True)\n",
    "        logits = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "    return logits.cpu().numpy()  # [N_images, N_texts]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 8) –°–∞–±–º–∏—Ç—ã (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è/—Ä–µ–≥—Ä–µ—Å—Å–∏—è/—Ç–µ–∫—Å—Ç) <a id=\"sec8\"></a>\n",
    "\n",
    "```markdown\n",
    "<div style=\"border:1px solid #333;padding:14px;border-radius:8px;background:#0f0f0f;color:#ddd\">\n",
    "<h2>üì§ 8. –°–∞–±–º–∏—Ç—ã</h2>\n",
    "<p>–¢—Ä–∏ —à–∞–±–ª–æ–Ω–∞ –ø–æ–¥ —Å–∞–º—ã–µ —á–∞—Å—Ç—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–π. –í—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è–π <code>sample_submission.csv</code>.</p>\n",
    "</div>\n",
    "```\n",
    "\n",
    "```python\n",
    "def save_classification_submission(test_df: pd.DataFrame, preds: Iterable, id_col=\"id\", target_col=\"label\",\n",
    "                                   path: str = \"submission_classification.csv\") -> pd.DataFrame:\n",
    "    sub = pd.DataFrame({id_col: test_df[id_col].values, target_col: list(preds)})\n",
    "    sub.to_csv(path, index=False)\n",
    "    logger.success(f\"–°–∞–±–º–∏—Ç (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è) —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {path} shape={sub.shape}\")\n",
    "    return sub\n",
    "\n",
    "def save_regression_submission(test_df: pd.DataFrame, preds: Iterable, id_col=\"id\", target_col=\"target\",\n",
    "                               path: str = \"submission_regression.csv\") -> pd.DataFrame:\n",
    "    sub = pd.DataFrame({id_col: test_df[id_col].values, target_col: list(preds)})\n",
    "    sub.to_csv(path, index=False)\n",
    "    logger.success(f\"–°–∞–±–º–∏—Ç (—Ä–µ–≥—Ä–µ—Å—Å–∏—è) —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {path} shape={sub.shape}\")\n",
    "    return sub\n",
    "\n",
    "def save_text_submission(test_df: pd.DataFrame, texts: List[str], id_col=\"id\", target_col=\"prediction\",\n",
    "                         path: str = \"submission_text.csv\") -> pd.DataFrame:\n",
    "    sub = pd.DataFrame({id_col: test_df[id_col].values, target_col: texts})\n",
    "    sub.to_csv(path, index=False)\n",
    "    logger.success(f\"–°–∞–±–º–∏—Ç (—Ç–µ–∫—Å—Ç) —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {path} shape={sub.shape}\")\n",
    "    return sub\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 9) –£—Ç–∏–ª–∏—Ç—ã (–ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ, –∫–æ–Ω—Ç—Ä–æ–ª—å –≤–µ—Ä—Å–∏–π) <a id=\"sec9\"></a>\n",
    "\n",
    "```markdown\n",
    "<div style=\"border:1px solid #333;padding:14px;border-radius:8px;background:#0f0f0f;color:#ddd\">\n",
    "<h2>üõ†Ô∏è 9. –£—Ç–∏–ª–∏—Ç—ã</h2>\n",
    "<p>–ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤, –±—ã—Å—Ç—Ä—ã–π —Ä–µ–ø–æ—Ä—Ç –æ–± –æ–∫—Ä—É–∂–µ–Ω–∏–∏.</p>\n",
    "</div>\n",
    "```\n",
    "\n",
    "```python\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def timer(name: str):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    dt = time.time() - t0\n",
    "    logger.info(f\"[TIMER] {name}: {dt:.3f}s\")\n",
    "\n",
    "def save_pickle(obj: Any, path: str):\n",
    "    import pickle\n",
    "    ensure_dir(os.path.dirname(path) or \".\")\n",
    "    with open(path, \"wb\") as f: pickle.dump(obj, f)\n",
    "    logger.success(f\"Pickle —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {path}\")\n",
    "\n",
    "def load_pickle_fast(path: str) -> Any:\n",
    "    import pickle\n",
    "    with open(path, \"rb\") as f: return pickle.load(f)\n",
    "\n",
    "def environment_report():\n",
    "    logger.info(f\"Python: {sys.version.split()[0]}\")\n",
    "    logger.info(f\"Platform: {sys.platform}\")\n",
    "    try:\n",
    "        import torch; logger.info(f\"Torch: {torch.__version__}, cuda={torch.cuda.is_available()}\")\n",
    "    except Exception: logger.warn(\"Torch: –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω\")\n",
    "    for lib in [\"lightgbm\",\"xgboost\",\"catboost\",\"sklearn\",\"pandas\",\"numpy\"]:\n",
    "        try:\n",
    "            m = __import__(lib); logger.info(f\"{lib}: {m.__version__}\")\n",
    "        except Exception:\n",
    "            logger.warn(f\"{lib}: –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω\")\n",
    "\n",
    "environment_report()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# ‚úÖ –ö–æ–Ω–µ—Ü —Ñ–∞–π–ª–∞\n",
    "\n",
    "–≠—Ç–æ—Ç —Ñ–∞–π–ª –º–æ–∂–Ω–æ –≤—Å—Ç–∞–≤–∏—Ç—å **–∫–∞–∫ –µ—Å—Ç—å** –≤ `README.md` –∏–ª–∏ Markdown-—è—á–µ–π–∫—É Jupyter.\n",
    "–•–æ—á–µ—à—å ‚Äî —Å–æ—Ç—Ä–∏ –≤—Å–µ `<div>‚Ä¶</div>` –æ–ø–∏—Å–∞–Ω–∏—è, –∏ –æ—Å—Ç–∞–Ω–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ **—á–∏—Å—Ç—ã–π —Ä–∞–±–æ—á–∏–π –∫–æ–¥**.\n",
    "\n",
    "–ï—Å–ª–∏ –Ω—É–∂–Ω–æ ‚Äî —Å–¥–µ–ª–∞—é —Ä—è–¥–æ–º **—á–∏—Å—Ç—É—é `.py` –≤–µ—Ä—Å–∏—é** —Ç–æ–≥–æ –∂–µ (–±–µ–∑ HTML/Markdown –≤—Å—Ç–∞–≤–æ–∫).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd10a5af-a3c4-44a3-ae76-1a6db8d3f2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
